{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GPSF1pX5gN70"
   },
   "source": [
    "## NLP sentence similarity project\n",
    "### Group: Sara Bonati - Irina Kokoshko\n",
    "\n",
    "This notebook applies a state of the art Transformer vector space model (BERT) to sentence data taken from 3 different datasets:\n",
    "\n",
    "*   A subset of news sentence pairs from the STS benchmark, which we refer to as STS1\n",
    "*   A bigger subset from the STS benchmark containing sentence pairs from news/captions/internet forums from 2012 to 2017, which we refer to as STSFull\n",
    "*   Semantically ambiguous sentence pairs used in a survey online, which we refer to as Survey\n",
    "\n",
    "In this notebook the BERT model is varied in terms of: \n",
    "*  hidden layers used (from 1 to 12 layers)\n",
    "*  aggregation strategy for the word embeddings derived from the hidden layers (average, concatenate or sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18012,
     "status": "ok",
     "timestamp": 1613982857817,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "1v7VKM_BgI5y",
    "outputId": "47f1272f-4b59-4da0-80d8-e000e0f9b741"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /usr/local/lib/python3.6/dist-packages (3.2.5)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from nltk) (1.15.0)\n",
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
      "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/wordnet.zip.\n",
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "Collecting transformers\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/98/87/ef312eef26f5cecd8b17ae9654cdd8d1fae1eb6dbd87257d6d73c128a4d0/transformers-4.3.2-py3-none-any.whl (1.8MB)\n",
      "\u001b[K     |████████████████████████████████| 1.8MB 7.6MB/s \n",
      "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
      "Collecting tokenizers<0.11,>=0.10.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/5b/44baae602e0a30bcc53fbdbc60bd940c15e143d252d658dfdefce736ece5/tokenizers-0.10.1-cp36-cp36m-manylinux2010_x86_64.whl (3.2MB)\n",
      "\u001b[K     |████████████████████████████████| 3.2MB 46.6MB/s \n",
      "\u001b[?25hCollecting sacremoses\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
      "\u001b[K     |████████████████████████████████| 890kB 37.3MB/s \n",
      "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.8)\n",
      "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
      "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (1.19.5)\n",
      "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (1.0.0)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
      "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.4.0)\n",
      "Building wheels for collected packages: sacremoses\n",
      "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893261 sha256=5cdd72ce37ac47b18f8a9332300377f03743fe25ecec22ab70bdceaeaa2e1f04\n",
      "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
      "Successfully built sacremoses\n",
      "Installing collected packages: tokenizers, sacremoses, transformers\n",
      "Successfully installed sacremoses-0.0.43 tokenizers-0.10.1 transformers-4.3.2\n"
     ]
    }
   ],
   "source": [
    "# general utility import\n",
    "#---------------------------------------------------------------\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pickle\n",
    "import math\n",
    "import pandas as pd\n",
    "import sys,io,pprint\n",
    "import re\n",
    "from functools import partial\n",
    "from tqdm import tqdm\n",
    "tqdm = partial(tqdm, position=0, leave=True)\n",
    "\n",
    "# nltk modules\n",
    "from __future__ import division\n",
    "!pip install nltk\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import wordnet as wn, stopwords\n",
    "from nltk.corpus import brown, gutenberg\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.data import find\n",
    "\n",
    "#BERT modules\n",
    "!pip install transformers\n",
    "import transformers\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertTokenizer, BertModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqNGXOuUMx9J"
   },
   "source": [
    "# STS1 dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4eUlslOAp89j"
   },
   "source": [
    "### Load data + sentence preprocessing + normalize score values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "executionInfo": {
     "elapsed": 19760,
     "status": "ok",
     "timestamp": 1613905011257,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "1whOgrTwhsJf",
    "outputId": "b51e8d8d-eaf7-464c-b500-77a4437d25b1"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SentenceA</th>\n",
       "      <th>SentenceB</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>micron has declared its first quarterly profit...</td>\n",
       "      <td>micron numbers also marked the first quarterly...</td>\n",
       "      <td>0.7500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>the fines are part of failed republican effort...</td>\n",
       "      <td>perry said he backs the senate efforts includi...</td>\n",
       "      <td>0.5600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>the tech loaded nasdaq composite rose 20 96 po...</td>\n",
       "      <td>the technology laced nasdaq composite index ix...</td>\n",
       "      <td>0.4800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>amgen shares gained 93 cents or 1 45 percent t...</td>\n",
       "      <td>shares of allergan were up 14 cents at 78 40 i...</td>\n",
       "      <td>0.2666</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>chavez said investigators feel confident they ...</td>\n",
       "      <td>albuquerque mayor martin chavez said investiga...</td>\n",
       "      <td>0.7600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           SentenceA  ...   Score\n",
       "1  micron has declared its first quarterly profit...  ...  0.7500\n",
       "2  the fines are part of failed republican effort...  ...  0.5600\n",
       "4  the tech loaded nasdaq composite rose 20 96 po...  ...  0.4800\n",
       "5  amgen shares gained 93 cents or 1 45 percent t...  ...  0.2666\n",
       "7  chavez said investigators feel confident they ...  ...  0.7600\n",
       "\n",
       "[5 rows x 3 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "#-------------------------------------------------------------------------------\n",
    "sts1 =pd.read_pickle('sentences_shorter.pkl') # change file directory if needed\n",
    "\n",
    "# preprocessing function\n",
    "#-------------------------------------------------------------------------------\n",
    "def preprocess_text(text):\n",
    "    # convert to string\n",
    "    text = str(text)\n",
    "    #lowercase\n",
    "    text = text.lower()\n",
    "    # Clean the text\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"she\\'s\", \"she is\", text)\n",
    "    text = re.sub(r\"it\\'s\", \"it is\", text)\n",
    "    text = re.sub(r\"he\\'s\", \"he is\", text)\n",
    "    text = re.sub(r\"[^A-Za-z0-9^,!.\\/'+-=]\", \" \", text)\n",
    "    text = re.sub(r\"what's\", \"what is \", text)\n",
    "    text = re.sub(r\"\\'s\", \" \", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have \", text)\n",
    "    text = re.sub(r\"can't\", \"cannot \", text)\n",
    "    text = re.sub(r\"n't\", \" not \", text)\n",
    "    text = re.sub(r\"i'm\", \"i am \", text)\n",
    "    text = re.sub(r\"\\'re\", \" are \", text)\n",
    "    text = re.sub(r\"\\'d\", \" would \", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will \", text)\n",
    "    text = re.sub(r\",\", \" \", text)\n",
    "    text = re.sub(r\"\\.\", \" \", text)\n",
    "    text = re.sub(r\"!\", \" ! \", text)\n",
    "    text = re.sub(r\"\\/\", \" \", text)\n",
    "    text = re.sub(r\"\\^\", \" ^ \", text)\n",
    "    text = re.sub(r\"\\+\", \" + \", text)\n",
    "    text = re.sub(r\"\\-\", \" \", text) \n",
    "    text = re.sub(r\"\\=\", \" = \", text)\n",
    "    text = re.sub(r\"\\<\", \"\", text) \n",
    "    text = re.sub(r\"\\>\", \"\", text) \n",
    "    text = re.sub(r\"'\", \" \", text)\n",
    "    text = re.sub(r\"(\\d+)(k)\", r\"\\g<1>000\", text)\n",
    "    text = re.sub(r\":\", \" : \", text)\n",
    "    text = re.sub(r\" e g \", \" eg \", text)\n",
    "    text = re.sub(r\" b g \", \" bg \", text)\n",
    "    text = re.sub(r\" u s \", \" american \", text)\n",
    "    text = re.sub(r\"\\0s\", \"0\", text)\n",
    "    text = re.sub(r\" 9 11 \", \"911\", text)\n",
    "    text = re.sub(r\"e - mail\", \"email\", text)\n",
    "    text = re.sub(r\"j k\", \"jk\", text)\n",
    "    text = re.sub(r\"\\s{2,}\", \" \", text)\n",
    "\n",
    "    tockens = text.split(' ')\n",
    "    # NO stopwords or lemmatization\n",
    "    tockens = [word for word in tockens]\n",
    "    return ' '.join([t for t in tockens])\n",
    "\n",
    "for index, row in sts1.iterrows():\n",
    "    sts1.loc[index, \"SentenceA\"] = preprocess_text(sts1.loc[index, \"SentenceA\"])\n",
    "    sts1.loc[index, \"SentenceB\"] = preprocess_text(sts1.loc[index, \"SentenceB\"])\n",
    "\n",
    "# normalize Score to be in range [0,1]\n",
    "sts1[\"Score\"] = sts1[\"Score\"]/5\n",
    "sts1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jZS6bZP_OFC-"
   },
   "source": [
    "## BERT model specification ( see also https://mccormickml.com/2019/05/14/BERT-word-embeddings-tutorial/) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "fbab3b2912a246acb796d22e4c13a48d",
      "11e48d8bc4c849239de556ea6bf8698c",
      "9bf155cba51a412486c972e41168d863",
      "9b4324d5b9a341e09e54cfbe31665b19",
      "303639e5451f40f6874033005b5246a7",
      "936f8f62197c4912887da8b135c9edaa",
      "f114a0a670814cc3a814d14ec00aee02",
      "42243a9ed0af44b8ba8fd3f5ba0f9704",
      "debb9bd561e94e1994b379a143b82247",
      "1bb2a2f5a62149fab6c891f42a688a53",
      "43ba3b28433b4822bbb266f9e65beeff",
      "3db710aeae2742d49e92b9ceb6000b8e",
      "d1f0fde993984933a74d621f862fd601",
      "d1fe201f14f94f8284ccad1eaf93bef9",
      "777f686bc8e8472382401b6658f96b21",
      "01662387a180465b948d30e20f8f660f",
      "b1af0142f97543c1b67f43810155f818",
      "244c661ccfce4e1094ad53c17a08d481",
      "3aae8ee4d34649808c68fe1c8d234ca2",
      "78f225744ee0476dbbe4f4988cf747c6",
      "fbba757a8bb8435c9ae858ec49ea1b2e",
      "34433c17bb104ba08dceb07d90013de5",
      "bf0d904f740b412f92f0db5ace5e330e",
      "4f1d90b0844244578b221b0a95320638"
     ]
    },
    "executionInfo": {
     "elapsed": 32053,
     "status": "ok",
     "timestamp": 1613905023567,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "HSuwAcPLOGcH",
    "outputId": "cda2079d-3568-4bff-ac1e-629e02996ac7"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fbab3b2912a246acb796d22e4c13a48d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "debb9bd561e94e1994b379a143b82247",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1af0142f97543c1b67f43810155f818",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize bert tokenizer\n",
    "bert_tokenizer  = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Load pre-trained model (weights)\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                        output_hidden_states = True)\n",
    "\n",
    "def bert_semantic_similarity(sentence1,sentence2,embedding_method,layers,sentence_vec=False):\n",
    "    \n",
    "    if layers>12:\n",
    "        print(\"Error! Maximum number of layers to use is 12\")\n",
    "        return None\n",
    "    \n",
    "    # Tokenize our sentence with the BERT tokenizer.\n",
    "    sentence1       = \"[CLS] \" + sentence1 + \" [SEP]\" \n",
    "    sentence2       = \"[CLS] \" + sentence2 + \" [SEP]\"\n",
    "    tokenized_text1 = bert_tokenizer.tokenize(sentence1)\n",
    "    tokenized_text2 = bert_tokenizer.tokenize(sentence2)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens1 = bert_tokenizer.convert_tokens_to_ids(tokenized_text1)    \n",
    "    indexed_tokens2 = bert_tokenizer.convert_tokens_to_ids(tokenized_text2)  \n",
    "\n",
    "    # Mark each of the tokens as belonging to sentence \"0\" and \"1\".\n",
    "    segments_ids1 = [0] * len(tokenized_text1) \n",
    "    segments_ids2 = [1] * len(tokenized_text2) \n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor1    = torch.tensor([indexed_tokens1])\n",
    "    segments_tensors1 = torch.tensor([segments_ids1])\n",
    "    tokens_tensor2    = torch.tensor([indexed_tokens2])\n",
    "    segments_tensors2 = torch.tensor([segments_ids2])\n",
    "\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    bert_model.eval()   \n",
    "\n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all 12 layers. \n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs1 = bert_model(tokens_tensor1, segments_tensors1)\n",
    "        outputs2 = bert_model(tokens_tensor2, segments_tensors2)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states1 = outputs1[2]\n",
    "        hidden_states2 = outputs2[2]\n",
    "\n",
    "    token_embeddings1 = torch.stack(hidden_states1, dim=0)\n",
    "    token_embeddings1 = torch.squeeze(token_embeddings1, dim=1)\n",
    "    token_embeddings1 = token_embeddings1.permute(1,0,2)\n",
    "    token_embeddings2 = torch.stack(hidden_states2, dim=0)\n",
    "    token_embeddings2 = torch.squeeze(token_embeddings2, dim=1)\n",
    "    token_embeddings2 = token_embeddings2.permute(1,0,2)\n",
    "\n",
    "    if embedding_method == \"concat\":\n",
    "        token_vecs_cat1   = torch.empty(len(token_embeddings1),768*layers)\n",
    "        token_vecs_cat2   = torch.empty(len(token_embeddings2),768*layers)\n",
    "    if embedding_method == \"average\" or embedding_method == \"sum\":\n",
    "        token_vecs_cat1   = torch.empty(len(token_embeddings1),768)\n",
    "        token_vecs_cat2   = torch.empty(len(token_embeddings2),768)\n",
    "\n",
    "    # For each token in the sentence 1...\n",
    "    for token in range(len(token_embeddings1)):\n",
    "\n",
    "        if embedding_method == \"concat\":\n",
    "            \n",
    "            if layers==1:\n",
    "                cat_vec1 = token_embeddings1[token][-1]\n",
    "            elif layers==2:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2]), dim=0)\n",
    "            elif layers==3:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3]), dim=0)\n",
    "            elif layers==4:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4]), dim=0)\n",
    "            elif layers==5:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5]), dim=0)\n",
    "            elif layers==6:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6]), dim=0)\n",
    "            elif layers==7:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7]), dim=0)\n",
    "            elif layers==8:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8]), dim=0)\n",
    "            elif layers==9:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8],\n",
    "                                      token_embeddings1[token][-9]), dim=0)\n",
    "            elif layers==10:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8],\n",
    "                                      token_embeddings1[token][-9],\n",
    "                                      token_embeddings1[token][-10]), dim=0)\n",
    "            elif layers==11:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8],\n",
    "                                      token_embeddings1[token][-9],\n",
    "                                      token_embeddings1[token][-10],\n",
    "                                      token_embeddings1[token][-11]), dim=0)\n",
    "            elif layers==12:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8],\n",
    "                                      token_embeddings1[token][-9],\n",
    "                                      token_embeddings1[token][-10],\n",
    "                                      token_embeddings1[token][-11],\n",
    "                                      token_embeddings1[token][-12]), dim=0)\n",
    "\n",
    "\n",
    "        if embedding_method == \"average\":\n",
    "            cat_vec1 = torch.mean(token_embeddings1[token][-layers:], dim=0)\n",
    "            \n",
    "        if embedding_method == \"sum\":\n",
    "            cat_vec1 = torch.sum(token_embeddings1[token][-layers:], dim=0)\n",
    "            \n",
    "        # embedding for token word (single word) \n",
    "        token_vecs_cat1[token,:]=cat_vec1\n",
    "    #sentence 1 embedding \n",
    "    sentence_embedding1 = torch.mean(token_vecs_cat1,dim=0)\n",
    "\n",
    "    # For each token in the sentence 2...\n",
    "    for token in range(len(token_embeddings2)):    \n",
    "        if embedding_method == \"concat\":\n",
    "            if layers==1:\n",
    "                cat_vec2 = token_embeddings2[token][-1]\n",
    "            elif layers==2:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2]), dim=0)\n",
    "            elif layers==3:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3]), dim=0)\n",
    "            elif layers==4:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4]), dim=0)\n",
    "            elif layers==5:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5]), dim=0)\n",
    "            elif layers==6:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6]), dim=0)\n",
    "            elif layers==7:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7]), dim=0)\n",
    "            elif layers==8:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8]), dim=0)\n",
    "            elif layers==9:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8],\n",
    "                                      token_embeddings2[token][-9]), dim=0)\n",
    "            elif layers==10:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8],\n",
    "                                      token_embeddings2[token][-9],\n",
    "                                      token_embeddings2[token][-10]), dim=0)\n",
    "            elif layers==11:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8],\n",
    "                                      token_embeddings2[token][-9],\n",
    "                                      token_embeddings2[token][-10],\n",
    "                                      token_embeddings2[token][-11]), dim=0)\n",
    "            elif layers==12:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8],\n",
    "                                      token_embeddings2[token][-9],\n",
    "                                      token_embeddings2[token][-10],\n",
    "                                      token_embeddings2[token][-11],\n",
    "                                      token_embeddings2[token][-12]), dim=0)\n",
    "\n",
    "            \n",
    "        if embedding_method == \"average\":\n",
    "            cat_vec2 = torch.mean(token_embeddings2[token][-layers:], dim=0)\n",
    "        if embedding_method == \"sum\":\n",
    "            cat_vec2 = torch.sum(token_embeddings2[token][-layers:], dim=0)\n",
    "        \n",
    "        token_vecs_cat2[token,:]=cat_vec2\n",
    "    # sentence embedding\n",
    "    sentence_embedding2 = torch.mean(token_vecs_cat2,dim=0)\n",
    "    \n",
    "    cos         = nn.CosineSimilarity(dim=0)\n",
    "    sem_sim     = cos(sentence_embedding1,sentence_embedding2)\n",
    "    return sem_sim.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3202092,
     "status": "ok",
     "timestamp": 1613908193615,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "ajCWfOB9OZ06",
    "outputId": "57d98bf8-aa63-4983-b907-823050db89b7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategy: average\n",
      "Start from final hidden layer and average:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:25<00:00,  4.59it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:36<00:00,  4.41it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:25<00:00,  4.59it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:25<00:00,  4.59it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:24<00:00,  4.61it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  6\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:20<00:00,  4.68it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:21<00:00,  4.65it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:20<00:00,  4.68it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:20<00:00,  4.68it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:22<00:00,  4.63it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  11\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:24<00:00,  4.60it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  12\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:23<00:00,  4.63it/s]\n"
     ]
    }
   ],
   "source": [
    "#average\n",
    "#------------------------------------------------------------------------------\n",
    "results_average     = np.zeros((len(sts1),12)) \n",
    "corrs_average       = np.zeros((12,1))\n",
    "print(\"Embedding strategy: average\")\n",
    "for i in range(12):\n",
    "    print(\"Start from final hidden layer and average: \",i+1)\n",
    "    print('\\n')\n",
    "    for s in tqdm(range(len(sts1))):\n",
    "            results_average[s,i] = bert_semantic_similarity(str(sts1.iloc[s,0]),\n",
    "                                                    str(sts1.iloc[s,1]),\n",
    "                                                    \"average\",\n",
    "                                                    i+1,\n",
    "                                                    False)\n",
    "    d = pd.DataFrame({'Score_BERT': results_average[:,i]})\n",
    "    corrs_average[i,0] = d[\"Score_BERT\"].corr(sts1[\"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3202087,
     "status": "ok",
     "timestamp": 1613908193618,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "micVnHsjx8Pg",
    "outputId": "c80cda06-e681-4dd4-dc4b-b5d93b28492a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20010996],\n",
       "       [0.2076047 ],\n",
       "       [0.20868153],\n",
       "       [0.21395806],\n",
       "       [0.21592632],\n",
       "       [0.21560297],\n",
       "       [0.21530191],\n",
       "       [0.21688952],\n",
       "       [0.21939925],\n",
       "       [0.22202356],\n",
       "       [0.22444178],\n",
       "       [0.22653227]])"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6364608,
     "status": "ok",
     "timestamp": 1613911356149,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "ppl_BcewxwQh",
    "outputId": "0fcc594a-644d-4f73-8733-3e0d9c0658c6"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategy: concatenate\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:22<00:00,  4.63it/s]\n",
      "100%|██████████| 1218/1218 [04:22<00:00,  4.63it/s]\n",
      "100%|██████████| 1218/1218 [04:23<00:00,  4.61it/s]\n",
      "100%|██████████| 1218/1218 [04:23<00:00,  4.62it/s]\n",
      "100%|██████████| 1218/1218 [04:26<00:00,  4.58it/s]\n",
      "100%|██████████| 1218/1218 [04:22<00:00,  4.64it/s]\n",
      "100%|██████████| 1218/1218 [04:23<00:00,  4.63it/s]\n",
      "100%|██████████| 1218/1218 [04:23<00:00,  4.61it/s]\n",
      "100%|██████████| 1218/1218 [04:22<00:00,  4.64it/s]\n",
      "100%|██████████| 1218/1218 [04:21<00:00,  4.65it/s]\n",
      "100%|██████████| 1218/1218 [04:24<00:00,  4.61it/s]\n",
      "100%|██████████| 1218/1218 [04:24<00:00,  4.60it/s]\n"
     ]
    }
   ],
   "source": [
    "#concat\n",
    "#------------------------------------------------------------------------------\n",
    "results_concat     = np.zeros((len(sts1),12)) \n",
    "corrs_concat       = np.zeros((12,1))\n",
    "print(\"Embedding strategy: concatenate\")\n",
    "for i in range(12):\n",
    "    print(\"Start from final hidden layer and concatenate: \",i+1)\n",
    "    print('\\n')\n",
    "    for s in tqdm(range(len(sts1))):\n",
    "            results_concat[s,i] = bert_semantic_similarity(str(sts1.iloc[s,0]),\n",
    "                                                    str(sts1.iloc[s,1]),\n",
    "                                                    \"concat\",\n",
    "                                                    i+1,\n",
    "                                                    False)\n",
    "    d = pd.DataFrame({'Score_BERT': results_concat[:,i]})\n",
    "    corrs_concat[i,0] = d[\"Score_BERT\"].corr(sts1[\"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6364605,
     "status": "ok",
     "timestamp": 1613911356154,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "Wmc5F0nuWxvX",
    "outputId": "a3fa5cd3-1a1e-44f6-8780-e390679c5655"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20010996],\n",
       "       [0.20617443],\n",
       "       [0.20719479],\n",
       "       [0.21101616],\n",
       "       [0.2125952 ],\n",
       "       [0.21362439],\n",
       "       [0.21418603],\n",
       "       [0.21683454],\n",
       "       [0.21990334],\n",
       "       [0.22271046],\n",
       "       [0.2255876 ],\n",
       "       [0.22908105]])"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9583728,
     "status": "ok",
     "timestamp": 1613914575284,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "98p4Vr7txz2t",
    "outputId": "465572fc-00f1-45d3-d338-680109e2e7a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategy: sum\n",
      "Start from final hidden layer and sum:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:25<00:00,  4.59it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:23<00:00,  4.62it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:28<00:00,  4.54it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:27<00:00,  4.55it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:30<00:00,  4.50it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  6\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:33<00:00,  4.46it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:30<00:00,  4.50it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:29<00:00,  4.52it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:28<00:00,  4.54it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:30<00:00,  4.50it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  11\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:26<00:00,  4.57it/s]\n",
      "  0%|          | 0/1218 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  12\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1218/1218 [04:25<00:00,  4.59it/s]\n"
     ]
    }
   ],
   "source": [
    "#sum\n",
    "#------------------------------------------------------------------------------\n",
    "results_sum     = np.zeros((len(sts1),12)) \n",
    "corrs_sum       = np.zeros((12,1))\n",
    "print(\"Embedding strategy: sum\")\n",
    "for i in range(12):\n",
    "    print(\"Start from final hidden layer and sum: \",i+1)\n",
    "    print('\\n')\n",
    "    for s in tqdm(range(len(sts1))):\n",
    "            results_sum[s,i] = bert_semantic_similarity(str(sts1.iloc[s,0]),\n",
    "                                                    str(sts1.iloc[s,1]),\n",
    "                                                    \"sum\",\n",
    "                                                    i+1,\n",
    "                                                    False)\n",
    "    d = pd.DataFrame({'Score_BERT': results_sum[:,i]})\n",
    "    corrs_sum[i,0] = d[\"Score_BERT\"].corr(sts1[\"Score\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9583722,
     "status": "ok",
     "timestamp": 1613914575286,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "uh1S4oK-9HZm",
    "outputId": "3032af2e-7051-42e8-d434-cfa06784f112"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.20010996],\n",
       "       [0.2076047 ],\n",
       "       [0.20868148],\n",
       "       [0.21395806],\n",
       "       [0.21592632],\n",
       "       [0.21560296],\n",
       "       [0.21530182],\n",
       "       [0.21688952],\n",
       "       [0.21939919],\n",
       "       [0.22202359],\n",
       "       [0.22444171],\n",
       "       [0.22653219]])"
      ]
     },
     "execution_count": 10,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gk1H6z1hO4Vt"
   },
   "outputs": [],
   "source": [
    "STS1survey = [corrs_average,corrs_concat,corrs_sum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9JusBwRIOIjU"
   },
   "source": [
    "# ---------------------------------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RV9NNvHouJ6h"
   },
   "source": [
    "# STS full dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data + sentence preprocessing + normalize score values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "executionInfo": {
     "elapsed": 7717,
     "status": "ok",
     "timestamp": 1613982880591,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "fHI_sQgTuIQY",
    "outputId": "d09b5450-8819-465d-8d75-9cd1c0a676a9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Skipping line 1525: '\t' expected after '\"'\n",
      "Skipping line 1542: '\t' expected after '\"'\n",
      "Skipping line 1614: '\t' expected after '\"'\n",
      "Skipping line 2002: '\t' expected after '\"'\n",
      "Skipping line 2003: '\t' expected after '\"'\n",
      "Skipping line 2006: '\t' expected after '\"'\n",
      "Skipping line 2020: '\t' expected after '\"'\n",
      "Skipping line 2026: '\t' expected after '\"'\n",
      "Skipping line 2030: '\t' expected after '\"'\n",
      "Skipping line 2031: '\t' expected after '\"'\n",
      "Skipping line 2035: '\t' expected after '\"'\n",
      "Skipping line 2037: '\t' expected after '\"'\n",
      "Skipping line 2048: '\t' expected after '\"'\n",
      "Skipping line 2055: '\t' expected after '\"'\n",
      "Skipping line 2072: '\t' expected after '\"'\n",
      "Skipping line 2073: '\t' expected after '\"'\n",
      "Skipping line 2076: '\t' expected after '\"'\n",
      "Skipping line 2080: '\t' expected after '\"'\n",
      "Skipping line 2083: '\t' expected after '\"'\n",
      "Skipping line 2090: '\t' expected after '\"'\n",
      "Skipping line 2094: '\t' expected after '\"'\n",
      "Skipping line 2096: '\t' expected after '\"'\n",
      "Skipping line 2097: '\t' expected after '\"'\n",
      "Skipping line 2099: '\t' expected after '\"'\n",
      "Skipping line 2124: '\t' expected after '\"'\n",
      "Skipping line 2127: '\t' expected after '\"'\n",
      "Skipping line 2194: '\t' expected after '\"'\n",
      "Skipping line 2233: '\t' expected after '\"'\n",
      "Skipping line 2237: '\t' expected after '\"'\n",
      "Skipping line 2247: '\t' expected after '\"'\n",
      "Skipping line 2258: '\t' expected after '\"'\n",
      "Skipping line 2263: '\t' expected after '\"'\n",
      "Skipping line 2289: '\t' expected after '\"'\n",
      "Skipping line 2292: '\t' expected after '\"'\n",
      "Skipping line 2298: '\t' expected after '\"'\n",
      "Skipping line 2305: '\t' expected after '\"'\n",
      "Skipping line 2326: '\t' expected after '\"'\n",
      "Skipping line 2352: '\t' expected after '\"'\n",
      "Skipping line 2365: '\t' expected after '\"'\n",
      "Skipping line 2372: '\t' expected after '\"'\n",
      "Skipping line 2377: '\t' expected after '\"'\n",
      "Skipping line 2392: '\t' expected after '\"'\n",
      "Skipping line 2393: '\t' expected after '\"'\n",
      "Skipping line 2394: '\t' expected after '\"'\n",
      "Skipping line 2409: '\t' expected after '\"'\n",
      "Skipping line 2410: '\t' expected after '\"'\n",
      "Skipping line 2425: '\t' expected after '\"'\n",
      "Skipping line 2447: '\t' expected after '\"'\n",
      "Skipping line 2453: '\t' expected after '\"'\n",
      "Skipping line 2461: '\t' expected after '\"'\n",
      "Skipping line 2473: '\t' expected after '\"'\n",
      "Skipping line 2479: '\t' expected after '\"'\n",
      "Skipping line 2482: '\t' expected after '\"'\n",
      "Skipping line 2488: '\t' expected after '\"'\n",
      "Skipping line 2499: '\t' expected after '\"'\n",
      "Skipping line 2512: '\t' expected after '\"'\n",
      "Skipping line 2517: '\t' expected after '\"'\n",
      "Skipping line 2520: '\t' expected after '\"'\n",
      "Skipping line 2522: '\t' expected after '\"'\n",
      "Skipping line 2528: '\t' expected after '\"'\n",
      "Skipping line 2529: '\t' expected after '\"'\n",
      "Skipping line 2532: '\t' expected after '\"'\n",
      "Skipping line 2533: '\t' expected after '\"'\n",
      "Skipping line 2539: '\t' expected after '\"'\n",
      "Skipping line 2553: '\t' expected after '\"'\n",
      "Skipping line 2559: '\t' expected after '\"'\n",
      "Skipping line 2561: '\t' expected after '\"'\n",
      "Skipping line 2564: '\t' expected after '\"'\n",
      "Skipping line 2571: '\t' expected after '\"'\n",
      "Skipping line 2576: '\t' expected after '\"'\n",
      "Skipping line 2582: '\t' expected after '\"'\n",
      "Skipping line 2583: '\t' expected after '\"'\n",
      "Skipping line 2584: '\t' expected after '\"'\n",
      "Skipping line 2587: '\t' expected after '\"'\n",
      "Skipping line 2607: '\t' expected after '\"'\n",
      "Skipping line 2610: '\t' expected after '\"'\n",
      "Skipping line 2614: '\t' expected after '\"'\n",
      "Skipping line 2622: '\t' expected after '\"'\n",
      "Skipping line 2631: '\t' expected after '\"'\n",
      "Skipping line 2640: '\t' expected after '\"'\n",
      "Skipping line 2647: '\t' expected after '\"'\n",
      "Skipping line 2658: '\t' expected after '\"'\n",
      "Skipping line 2663: '\t' expected after '\"'\n",
      "Skipping line 2664: '\t' expected after '\"'\n",
      "Skipping line 2665: '\t' expected after '\"'\n",
      "Skipping line 2666: '\t' expected after '\"'\n",
      "Skipping line 2671: '\t' expected after '\"'\n",
      "Skipping line 2674: '\t' expected after '\"'\n",
      "Skipping line 2677: '\t' expected after '\"'\n",
      "Skipping line 2683: '\t' expected after '\"'\n",
      "Skipping line 2685: '\t' expected after '\"'\n",
      "Skipping line 2689: '\t' expected after '\"'\n",
      "Skipping line 2695: '\t' expected after '\"'\n",
      "Skipping line 2716: '\t' expected after '\"'\n",
      "Skipping line 2723: '\t' expected after '\"'\n",
      "Skipping line 2729: '\t' expected after '\"'\n",
      "Skipping line 2740: '\t' expected after '\"'\n",
      "Skipping line 2748: '\t' expected after '\"'\n",
      "Skipping line 2776: '\t' expected after '\"'\n",
      "Skipping line 2792: '\t' expected after '\"'\n",
      "Skipping line 2795: '\t' expected after '\"'\n",
      "Skipping line 2803: '\t' expected after '\"'\n",
      "Skipping line 2810: '\t' expected after '\"'\n",
      "Skipping line 2814: '\t' expected after '\"'\n",
      "Skipping line 2820: '\t' expected after '\"'\n",
      "Skipping line 2821: '\t' expected after '\"'\n",
      "Skipping line 2822: '\t' expected after '\"'\n",
      "Skipping line 2827: '\t' expected after '\"'\n",
      "Skipping line 2828: '\t' expected after '\"'\n",
      "Skipping line 2829: '\t' expected after '\"'\n",
      "Skipping line 2834: '\t' expected after '\"'\n",
      "Skipping line 2837: '\t' expected after '\"'\n",
      "Skipping line 2845: '\t' expected after '\"'\n",
      "Skipping line 2847: '\t' expected after '\"'\n",
      "Skipping line 2857: '\t' expected after '\"'\n",
      "Skipping line 2859: '\t' expected after '\"'\n",
      "Skipping line 2861: '\t' expected after '\"'\n",
      "Skipping line 2876: '\t' expected after '\"'\n",
      "Skipping line 2879: '\t' expected after '\"'\n",
      "Skipping line 2884: '\t' expected after '\"'\n",
      "Skipping line 2887: '\t' expected after '\"'\n",
      "Skipping line 2899: '\t' expected after '\"'\n",
      "Skipping line 2908: '\t' expected after '\"'\n",
      "Skipping line 2909: '\t' expected after '\"'\n",
      "Skipping line 2916: '\t' expected after '\"'\n",
      "Skipping line 2917: '\t' expected after '\"'\n",
      "Skipping line 2918: '\t' expected after '\"'\n",
      "Skipping line 2924: '\t' expected after '\"'\n",
      "Skipping line 2936: '\t' expected after '\"'\n",
      "Skipping line 2938: '\t' expected after '\"'\n",
      "Skipping line 2941: '\t' expected after '\"'\n",
      "Skipping line 2946: '\t' expected after '\"'\n",
      "Skipping line 2959: '\t' expected after '\"'\n",
      "Skipping line 2970: '\t' expected after '\"'\n",
      "Skipping line 2979: '\t' expected after '\"'\n",
      "Skipping line 2985: '\t' expected after '\"'\n",
      "Skipping line 3000: '\t' expected after '\"'\n",
      "Skipping line 3001: '\t' expected after '\"'\n",
      "Skipping line 3002: '\t' expected after '\"'\n",
      "Skipping line 3010: '\t' expected after '\"'\n",
      "Skipping line 3017: '\t' expected after '\"'\n",
      "Skipping line 3025: '\t' expected after '\"'\n",
      "Skipping line 3037: '\t' expected after '\"'\n",
      "Skipping line 3045: '\t' expected after '\"'\n",
      "Skipping line 3046: '\t' expected after '\"'\n",
      "Skipping line 3050: '\t' expected after '\"'\n",
      "Skipping line 3051: '\t' expected after '\"'\n",
      "Skipping line 3057: '\t' expected after '\"'\n",
      "Skipping line 3061: '\t' expected after '\"'\n",
      "Skipping line 3064: '\t' expected after '\"'\n",
      "Skipping line 3066: '\t' expected after '\"'\n",
      "Skipping line 3071: '\t' expected after '\"'\n",
      "Skipping line 3077: '\t' expected after '\"'\n",
      "Skipping line 3078: '\t' expected after '\"'\n",
      "Skipping line 3084: '\t' expected after '\"'\n",
      "Skipping line 3092: '\t' expected after '\"'\n",
      "Skipping line 3093: '\t' expected after '\"'\n",
      "Skipping line 3096: '\t' expected after '\"'\n",
      "Skipping line 3097: '\t' expected after '\"'\n",
      "Skipping line 3098: '\t' expected after '\"'\n",
      "Skipping line 3100: '\t' expected after '\"'\n",
      "Skipping line 3103: '\t' expected after '\"'\n",
      "Skipping line 3108: '\t' expected after '\"'\n",
      "Skipping line 3109: '\t' expected after '\"'\n",
      "Skipping line 3118: '\t' expected after '\"'\n",
      "Skipping line 3119: '\t' expected after '\"'\n",
      "Skipping line 3130: '\t' expected after '\"'\n",
      "Skipping line 3134: '\t' expected after '\"'\n",
      "Skipping line 3137: '\t' expected after '\"'\n",
      "Skipping line 3138: '\t' expected after '\"'\n",
      "Skipping line 3139: '\t' expected after '\"'\n",
      "Skipping line 3152: '\t' expected after '\"'\n",
      "Skipping line 3162: '\t' expected after '\"'\n",
      "Skipping line 3164: '\t' expected after '\"'\n",
      "Skipping line 3185: '\t' expected after '\"'\n",
      "Skipping line 3187: '\t' expected after '\"'\n",
      "Skipping line 3188: '\t' expected after '\"'\n",
      "Skipping line 3194: '\t' expected after '\"'\n",
      "Skipping line 3197: '\t' expected after '\"'\n",
      "Skipping line 3205: '\t' expected after '\"'\n",
      "Skipping line 3207: '\t' expected after '\"'\n",
      "Skipping line 3218: '\t' expected after '\"'\n",
      "Skipping line 3225: '\t' expected after '\"'\n",
      "Skipping line 3230: '\t' expected after '\"'\n",
      "Skipping line 3232: '\t' expected after '\"'\n",
      "Skipping line 3244: '\t' expected after '\"'\n",
      "Skipping line 3245: '\t' expected after '\"'\n",
      "Skipping line 3246: '\t' expected after '\"'\n",
      "Skipping line 3249: '\t' expected after '\"'\n",
      "Skipping line 3253: '\t' expected after '\"'\n",
      "Skipping line 3261: '\t' expected after '\"'\n",
      "Skipping line 3270: '\t' expected after '\"'\n",
      "Skipping line 3278: '\t' expected after '\"'\n",
      "Skipping line 3280: '\t' expected after '\"'\n",
      "Skipping line 3283: '\t' expected after '\"'\n",
      "Skipping line 3290: '\t' expected after '\"'\n",
      "Skipping line 3294: '\t' expected after '\"'\n",
      "Skipping line 3297: '\t' expected after '\"'\n",
      "Skipping line 3298: '\t' expected after '\"'\n",
      "Skipping line 3299: '\t' expected after '\"'\n",
      "Skipping line 3305: '\t' expected after '\"'\n",
      "Skipping line 3313: '\t' expected after '\"'\n",
      "Skipping line 3316: '\t' expected after '\"'\n",
      "Skipping line 3327: '\t' expected after '\"'\n",
      "Skipping line 3334: '\t' expected after '\"'\n",
      "Skipping line 3335: '\t' expected after '\"'\n",
      "Skipping line 3336: '\t' expected after '\"'\n",
      "Skipping line 3340: '\t' expected after '\"'\n",
      "Skipping line 3341: '\t' expected after '\"'\n",
      "Skipping line 3351: '\t' expected after '\"'\n",
      "Skipping line 3357: '\t' expected after '\"'\n",
      "Skipping line 3360: '\t' expected after '\"'\n",
      "Skipping line 3361: '\t' expected after '\"'\n",
      "Skipping line 3366: '\t' expected after '\"'\n",
      "Skipping line 3377: '\t' expected after '\"'\n",
      "Skipping line 3384: '\t' expected after '\"'\n",
      "Skipping line 3392: '\t' expected after '\"'\n",
      "Skipping line 3407: '\t' expected after '\"'\n",
      "Skipping line 3414: '\t' expected after '\"'\n",
      "Skipping line 3416: '\t' expected after '\"'\n",
      "Skipping line 3417: '\t' expected after '\"'\n",
      "Skipping line 3426: '\t' expected after '\"'\n",
      "Skipping line 3428: '\t' expected after '\"'\n",
      "Skipping line 3429: '\t' expected after '\"'\n",
      "Skipping line 3434: '\t' expected after '\"'\n",
      "Skipping line 3435: '\t' expected after '\"'\n",
      "Skipping line 3437: '\t' expected after '\"'\n",
      "Skipping line 3701: '\t' expected after '\"'\n",
      "Skipping line 3797: '\t' expected after '\"'\n",
      "Skipping line 4041: '\t' expected after '\"'\n",
      "Skipping line 4140: '\t' expected after '\"'\n",
      "Skipping line 4230: '\t' expected after '\"'\n",
      "Skipping line 4278: '\t' expected after '\"'\n",
      "Skipping line 4418: '\t' expected after '\"'\n",
      "Skipping line 4441: '\t' expected after '\"'\n",
      "Skipping line 4650: '\t' expected after '\"'\n",
      "Skipping line 4673: '\t' expected after '\"'\n",
      "Skipping line 4808: '\t' expected after '\"'\n",
      "Skipping line 5011: '\t' expected after '\"'\n",
      "Skipping line 5336: '\t' expected after '\"'\n",
      "Skipping line 5343: '\t' expected after '\"'\n",
      "Skipping line 5620: '\t' expected after '\"'\n",
      "Skipping line 5650: '\t' expected after '\"'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "do you understand why it is absurd to limit the question to us residents \n",
      "do you understand why non us residents are also relevant to the statistics \n",
      "the russian foreign ministry stated that russia has not suspended dialogue \n",
      "russian officials stated that russia will not reconsider the suspension \n",
      "illegal arms trafficking increases in kenya due to easy availability and neighboring conflicts \n",
      "illegal arms trafficking has increased in kenya and raised concern about security \n",
      "washington acts of congress sells for 9 8m\n",
      "george washington copy of us constitution sells for 9 8m\n",
      "philippines rebels reach wealth sharing deal\n",
      "philippines and rebels reach wealth deal \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>subtype</th>\n",
       "      <th>year</th>\n",
       "      <th>id</th>\n",
       "      <th>sim</th>\n",
       "      <th>sent_1</th>\n",
       "      <th>sent_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>a plane is taking off</td>\n",
       "      <td>an air plane is taking off</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>4</td>\n",
       "      <td>0.76</td>\n",
       "      <td>a man is playing a large flute</td>\n",
       "      <td>a man is playing a flute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>5</td>\n",
       "      <td>0.76</td>\n",
       "      <td>a man is spreading shreded cheese on a pizza</td>\n",
       "      <td>a man is spreading shredded cheese on an uncoo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>6</td>\n",
       "      <td>0.52</td>\n",
       "      <td>three men are playing chess</td>\n",
       "      <td>two men are playing chess</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>main-captions</td>\n",
       "      <td>MSRvid</td>\n",
       "      <td>2012test</td>\n",
       "      <td>9</td>\n",
       "      <td>0.85</td>\n",
       "      <td>a man is playing the cello</td>\n",
       "      <td>a man seated is playing the cello</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            type  ...                                             sent_2\n",
       "0  main-captions  ...                        an air plane is taking off \n",
       "1  main-captions  ...                          a man is playing a flute \n",
       "2  main-captions  ...  a man is spreading shredded cheese on an uncoo...\n",
       "3  main-captions  ...                         two men are playing chess \n",
       "4  main-captions  ...                 a man seated is playing the cello \n",
       "\n",
       "[5 rows x 7 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read data\n",
    "#-------------------------------------------------------------------------------\n",
    "stsfull =pd.read_csv('sts.txt',engine='python',sep='\\t', quotechar='\"',header=0,error_bad_lines=False)\n",
    "\n",
    "# preprocessing function (see cells above)\n",
    "#-------------------------------------------------------------------------------\n",
    "for index, row in stsfull.iterrows():\n",
    "    stsfull.loc[index, \"sent_1\"] = preprocess_text(stsfull.loc[index, \"sent_1\"])\n",
    "    stsfull.loc[index, \"sent_2\"] = preprocess_text(stsfull.loc[index, \"sent_2\"])\n",
    "    #print a few examples\n",
    "    if index in [4000,4500,3400,2345,3331]:\n",
    "        print(stsfull.loc[index, \"sent_1\"])\n",
    "        print(stsfull.loc[index, \"sent_2\"])\n",
    "\n",
    "# normalize Score to be in range [0,1]\n",
    "stsfull[\"sim\"] = stsfull[\"sim\"]/5\n",
    "stsfull.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 164,
     "referenced_widgets": [
      "413384e00a07494285700f23c8b02020",
      "8363e1fe667943ebad3cb9e4ff323cec",
      "a840bd9b4b5a416bab9fddeff8ffee78",
      "c2bae92977564ad595514b20d2761d09",
      "56d307adf23743a38cd4e6ec6a589652",
      "12c2f2a6af8e4e41ae772a87bb662dc6",
      "47f5a517613e43c0a4aedf09d737cacf",
      "3aac7e2da9ac4f9b8ea0ab0ba7322b1a",
      "c5ad14ec5aed40f49b921a8aee7a55c8",
      "d57100b06bb942acb4ee8eda405caae3",
      "fe98e7a6fee84dbd828f62ca22b02672",
      "30e03847d24b4147b9f04ac65500eea8",
      "00c146ccb5c348928aed2062ed86cb49",
      "6ead35d34c5843e48b47815393c0e28a",
      "cd27dc0d2c374be8a7cab7fbc208e68c",
      "ac0816f5a0b941d7882c08f86256b72d",
      "66e00e78fef14b76826a551e783d849e",
      "c2b801e36b784b9989204fe51e2a2f03",
      "e45d520c20fd49dd83c32637f8a59f36",
      "d37458ea10b54a4ba7a3e4a0905b3767",
      "3b10debb7dbb475ebd6688aafe35f467",
      "3ae3ec03f4204d51a8a4561bc9bb6721",
      "f2d8851289ef44f183a264aed1d92ce8",
      "bbe0e87791e64f249130d09446c5ae1e"
     ]
    },
    "executionInfo": {
     "elapsed": 13969,
     "status": "ok",
     "timestamp": 1613982900873,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "0M2rR4JyqXwg",
    "outputId": "d46bb88f-0df7-46f2-c7f7-4165d6458749"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "413384e00a07494285700f23c8b02020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=231508.0, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c5ad14ec5aed40f49b921a8aee7a55c8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=433.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "66e00e78fef14b76826a551e783d849e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=440473133.0, style=ProgressStyle(descri…"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# initialize bert tokenizer\n",
    "bert_tokenizer  = BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "# Load pre-trained model (weights)\n",
    "bert_model = BertModel.from_pretrained('bert-base-uncased',\n",
    "                                        output_hidden_states = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Y4idErFisPNz"
   },
   "outputs": [],
   "source": [
    "def bert_semantic_similarity(sentence1,sentence2,embedding_method,layers,sentence_vec=False):\n",
    "    \n",
    "    if layers>12:\n",
    "        print(\"Error! Maximum number of layers to use is 12\")\n",
    "        return None\n",
    "    \n",
    "    # Tokenize our sentence with the BERT tokenizer.\n",
    "    sentence1       = \"[CLS] \" + sentence1 + \" [SEP]\" \n",
    "    sentence2       = \"[CLS] \" + sentence2 + \" [SEP]\"\n",
    "    tokenized_text1 = bert_tokenizer.tokenize(sentence1)\n",
    "    tokenized_text2 = bert_tokenizer.tokenize(sentence2)\n",
    "\n",
    "    # Map the token strings to their vocabulary indeces.\n",
    "    indexed_tokens1 = bert_tokenizer.convert_tokens_to_ids(tokenized_text1)    \n",
    "    indexed_tokens2 = bert_tokenizer.convert_tokens_to_ids(tokenized_text2)  \n",
    "\n",
    "    # Mark each of the tokens as belonging to sentence \"0\" and \"1\".\n",
    "    segments_ids1 = [0] * len(tokenized_text1) \n",
    "    segments_ids2 = [1] * len(tokenized_text2) \n",
    "\n",
    "    # Convert inputs to PyTorch tensors\n",
    "    tokens_tensor1    = torch.tensor([indexed_tokens1])\n",
    "    segments_tensors1 = torch.tensor([segments_ids1])\n",
    "    tokens_tensor2    = torch.tensor([indexed_tokens2])\n",
    "    segments_tensors2 = torch.tensor([segments_ids2])\n",
    "\n",
    "    # Put the model in \"evaluation\" mode, meaning feed-forward operation.\n",
    "    bert_model.eval()   \n",
    "\n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all 12 layers. \n",
    "    with torch.no_grad():\n",
    "\n",
    "        outputs1 = bert_model(tokens_tensor1, segments_tensors1)\n",
    "        outputs2 = bert_model(tokens_tensor2, segments_tensors2)\n",
    "\n",
    "        # Evaluating the model will return a different number of objects based on \n",
    "        # how it's  configured in the `from_pretrained` call earlier. In this case, \n",
    "        # becase we set `output_hidden_states = True`, the third item will be the \n",
    "        # hidden states from all layers. See the documentation for more details:\n",
    "        # https://huggingface.co/transformers/model_doc/bert.html#bertmodel\n",
    "        hidden_states1 = outputs1[2]\n",
    "        hidden_states2 = outputs2[2]\n",
    "\n",
    "    token_embeddings1 = torch.stack(hidden_states1, dim=0)\n",
    "    token_embeddings1 = torch.squeeze(token_embeddings1, dim=1)\n",
    "    token_embeddings1 = token_embeddings1.permute(1,0,2)\n",
    "    token_embeddings2 = torch.stack(hidden_states2, dim=0)\n",
    "    token_embeddings2 = torch.squeeze(token_embeddings2, dim=1)\n",
    "    token_embeddings2 = token_embeddings2.permute(1,0,2)\n",
    "\n",
    "    if embedding_method == \"concat\":\n",
    "        token_vecs_cat1   = torch.empty(len(token_embeddings1),768*layers)\n",
    "        token_vecs_cat2   = torch.empty(len(token_embeddings2),768*layers)\n",
    "    if embedding_method == \"average\" or embedding_method == \"sum\":\n",
    "        token_vecs_cat1   = torch.empty(len(token_embeddings1),768)\n",
    "        token_vecs_cat2   = torch.empty(len(token_embeddings2),768)\n",
    "\n",
    "    # For each token in the sentence 1...\n",
    "    for token in range(len(token_embeddings1)):\n",
    "\n",
    "        if embedding_method == \"concat\":\n",
    "            \n",
    "            if layers==1:\n",
    "                cat_vec1 = token_embeddings1[token][-1]\n",
    "            elif layers==2:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2]), dim=0)\n",
    "            elif layers==3:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3]), dim=0)\n",
    "            elif layers==4:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4]), dim=0)\n",
    "            elif layers==5:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5]), dim=0)\n",
    "            elif layers==6:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6]), dim=0)\n",
    "            elif layers==7:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7]), dim=0)\n",
    "            elif layers==8:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8]), dim=0)\n",
    "            elif layers==9:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8],\n",
    "                                      token_embeddings1[token][-9]), dim=0)\n",
    "            elif layers==10:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8],\n",
    "                                      token_embeddings1[token][-9],\n",
    "                                      token_embeddings1[token][-10]), dim=0)\n",
    "            elif layers==11:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8],\n",
    "                                      token_embeddings1[token][-9],\n",
    "                                      token_embeddings1[token][-10],\n",
    "                                      token_embeddings1[token][-11]), dim=0)\n",
    "            elif layers==12:\n",
    "                cat_vec1 = torch.cat((token_embeddings1[token][-1],\n",
    "                                      token_embeddings1[token][-2],\n",
    "                                      token_embeddings1[token][-3],\n",
    "                                      token_embeddings1[token][-4],\n",
    "                                      token_embeddings1[token][-5],\n",
    "                                      token_embeddings1[token][-6],\n",
    "                                      token_embeddings1[token][-7],\n",
    "                                      token_embeddings1[token][-8],\n",
    "                                      token_embeddings1[token][-9],\n",
    "                                      token_embeddings1[token][-10],\n",
    "                                      token_embeddings1[token][-11],\n",
    "                                      token_embeddings1[token][-12]), dim=0)\n",
    "\n",
    "\n",
    "        if embedding_method == \"average\":\n",
    "            cat_vec1 = torch.mean(token_embeddings1[token][-layers:], dim=0)\n",
    "            \n",
    "        if embedding_method == \"sum\":\n",
    "            cat_vec1 = torch.sum(token_embeddings1[token][-layers:], dim=0)\n",
    "            \n",
    "        # embedding for token word (single word) \n",
    "        token_vecs_cat1[token,:]=cat_vec1\n",
    "    #sentence 1 embedding \n",
    "    sentence_embedding1 = torch.mean(token_vecs_cat1,dim=0)\n",
    "\n",
    "    # For each token in the sentence 2...\n",
    "    for token in range(len(token_embeddings2)):    \n",
    "        if embedding_method == \"concat\":\n",
    "            if layers==1:\n",
    "                cat_vec2 = token_embeddings2[token][-1]\n",
    "            elif layers==2:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2]), dim=0)\n",
    "            elif layers==3:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3]), dim=0)\n",
    "            elif layers==4:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4]), dim=0)\n",
    "            elif layers==5:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5]), dim=0)\n",
    "            elif layers==6:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6]), dim=0)\n",
    "            elif layers==7:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7]), dim=0)\n",
    "            elif layers==8:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8]), dim=0)\n",
    "            elif layers==9:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8],\n",
    "                                      token_embeddings2[token][-9]), dim=0)\n",
    "            elif layers==10:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8],\n",
    "                                      token_embeddings2[token][-9],\n",
    "                                      token_embeddings2[token][-10]), dim=0)\n",
    "            elif layers==11:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8],\n",
    "                                      token_embeddings2[token][-9],\n",
    "                                      token_embeddings2[token][-10],\n",
    "                                      token_embeddings2[token][-11]), dim=0)\n",
    "            elif layers==12:\n",
    "                cat_vec2 = torch.cat((token_embeddings2[token][-1],\n",
    "                                      token_embeddings2[token][-2],\n",
    "                                      token_embeddings2[token][-3],\n",
    "                                      token_embeddings2[token][-4],\n",
    "                                      token_embeddings2[token][-5],\n",
    "                                      token_embeddings2[token][-6],\n",
    "                                      token_embeddings2[token][-7],\n",
    "                                      token_embeddings2[token][-8],\n",
    "                                      token_embeddings2[token][-9],\n",
    "                                      token_embeddings2[token][-10],\n",
    "                                      token_embeddings2[token][-11],\n",
    "                                      token_embeddings2[token][-12]), dim=0)\n",
    "\n",
    "            \n",
    "        if embedding_method == \"average\":\n",
    "            cat_vec2 = torch.mean(token_embeddings2[token][-layers:], dim=0)\n",
    "        if embedding_method == \"sum\":\n",
    "            cat_vec2 = torch.sum(token_embeddings2[token][-layers:], dim=0)\n",
    "        \n",
    "        token_vecs_cat2[token,:]=cat_vec2\n",
    "    # sentence embedding\n",
    "    sentence_embedding2 = torch.mean(token_vecs_cat2,dim=0)\n",
    "    \n",
    "    cos         = nn.CosineSimilarity(dim=0)\n",
    "    sem_sim     = cos(sentence_embedding1,sentence_embedding2)\n",
    "    return sem_sim.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 23703752,
     "status": "ok",
     "timestamp": 1613928695342,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "RR6OEoPAryk9",
    "outputId": "843cdf8f-4d05-4249-bc2f-d375ee442bb5"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategy: average\n",
      "-----------------------------------------------------------------------\n",
      "Start from final hidden layer and average:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:20<00:00,  4.51it/s]\n",
      "  0%|          | 1/5506 [00:00<16:57,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:35<00:00,  4.69it/s]\n",
      "  0%|          | 1/5506 [00:00<16:19,  5.62it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:34<00:00,  4.69it/s]\n",
      "  0%|          | 1/5506 [00:00<16:21,  5.61it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:28<00:00,  4.71it/s]\n",
      "  0%|          | 1/5506 [00:00<15:55,  5.76it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:26<00:00,  4.72it/s]\n",
      "  0%|          | 1/5506 [00:00<17:01,  5.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  6\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:29<00:00,  4.71it/s]\n",
      "  0%|          | 1/5506 [00:00<16:43,  5.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:35<00:00,  4.69it/s]\n",
      "  0%|          | 1/5506 [00:00<17:23,  5.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:36<00:00,  4.68it/s]\n",
      "  0%|          | 1/5506 [00:00<16:44,  5.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:27<00:00,  4.72it/s]\n",
      "  0%|          | 0/5506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:30<00:00,  4.70it/s]\n",
      "  0%|          | 1/5506 [00:00<16:33,  5.54it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  11\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:28<00:00,  4.71it/s]\n",
      "  0%|          | 1/5506 [00:00<16:56,  5.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  12\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:33<00:00,  4.69it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.54571588],\n",
       "       [0.55601959],\n",
       "       [0.55286227],\n",
       "       [0.55074705],\n",
       "       [0.55759656],\n",
       "       [0.56365985],\n",
       "       [0.56978935],\n",
       "       [0.57645434],\n",
       "       [0.58311187],\n",
       "       [0.59148556],\n",
       "       [0.60128193],\n",
       "       [0.61130921]])"
      ]
     },
     "execution_count": 15,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#average\n",
    "#-------------------------------------------------------------------------------\n",
    "results_average     = np.zeros((len(stsfull),12)) \n",
    "corrs_average       = np.zeros((12,1))\n",
    "print(\"Embedding strategy: average\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "for i in range(12):\n",
    "    print(\"Start from final hidden layer and average: \",i+1)\n",
    "    print('\\n')\n",
    "    for s in tqdm(range(len(stsfull))):\n",
    "            results_average[s,i] = bert_semantic_similarity(str(stsfull.iloc[s,5]),\n",
    "                                                    str(stsfull.iloc[s,6]),\n",
    "                                                    \"average\",\n",
    "                                                    i+1,\n",
    "                                                    False)\n",
    "    d = pd.DataFrame({'Score_BERT': results_average[:,i]})\n",
    "    corrs_average[i,0] = d[\"Score_BERT\"].corr(stsfull[\"sim\"])\n",
    "\n",
    "corrs_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 13831634,
     "status": "ok",
     "timestamp": 1613943308736,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "Nmt_w4U_OX7Q",
    "outputId": "a0ada79c-d3c7-476f-c9a7-fba76798a8f3"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategy: concat\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [19:39<00:00,  4.67it/s]\n",
      "100%|██████████| 5506/5506 [19:34<00:00,  4.69it/s]\n",
      "100%|██████████| 5506/5506 [19:11<00:00,  4.78it/s]\n",
      "100%|██████████| 5506/5506 [19:01<00:00,  4.82it/s]\n",
      "100%|██████████| 5506/5506 [19:01<00:00,  4.82it/s]\n",
      "100%|██████████| 5506/5506 [19:07<00:00,  4.80it/s]\n",
      "100%|██████████| 5506/5506 [19:07<00:00,  4.80it/s]\n",
      "100%|██████████| 5506/5506 [19:10<00:00,  4.78it/s]\n",
      "100%|██████████| 5506/5506 [19:09<00:00,  4.79it/s]\n",
      "100%|██████████| 5506/5506 [19:04<00:00,  4.81it/s]\n",
      "100%|██████████| 5506/5506 [19:09<00:00,  4.79it/s]\n",
      "100%|██████████| 5506/5506 [19:12<00:00,  4.78it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.54571588],\n",
       "       [0.55199919],\n",
       "       [0.54735038],\n",
       "       [0.54294713],\n",
       "       [0.54668375],\n",
       "       [0.55087216],\n",
       "       [0.55500596],\n",
       "       [0.56002039],\n",
       "       [0.56489546],\n",
       "       [0.57168385],\n",
       "       [0.58111416],\n",
       "       [0.59094402]])"
      ]
     },
     "execution_count": 18,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#concat  \n",
    "#-------------------------------------------------------------------------------\n",
    "results_concat    = np.zeros((len(stsfull),12)) \n",
    "corrs_concat       = np.zeros((12,1))\n",
    "print(\"Embedding strategy: concat\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "for i in range(12):\n",
    "    print(\"Start from final hidden layer and concatenate: \",i+1)\n",
    "    print('\\n')\n",
    "    for s in tqdm(range(len(stsfull))):\n",
    "        results_concat[s,i] = bert_semantic_similarity(str(stsfull.iloc[s,5]),\n",
    "                                                str(stsfull.iloc[s,6]),\n",
    "                                                \"concat\",\n",
    "                                                i+1,\n",
    "                                                False)\n",
    "    d = pd.DataFrame({'Score_BERT': results_concat[:,i]})\n",
    "    corrs_concat[i,0] = d[\"Score_BERT\"].corr(stsfull[\"sim\"])\n",
    "corrs_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14974921,
     "status": "ok",
     "timestamp": 1613997898523,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "dkWKnZpcOaJ8",
    "outputId": "b308b3d7-aee1-4bc1-af0f-d318ddc14b1e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|          | 0/5506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategy: sum\n",
      "-----------------------------------------------------------------------\n",
      "Start from final hidden layer and sum:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:50<00:00,  4.40it/s]\n",
      "  0%|          | 0/5506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:42<00:00,  4.43it/s]\n",
      "  0%|          | 0/5506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:42<00:00,  4.43it/s]\n",
      "  0%|          | 0/5506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:37<00:00,  4.45it/s]\n",
      "  0%|          | 0/5506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:40<00:00,  4.44it/s]\n",
      "  0%|          | 1/5506 [00:00<17:52,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  6\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:34<00:00,  4.46it/s]\n",
      "  0%|          | 1/5506 [00:00<17:44,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:51<00:00,  4.40it/s]\n",
      "  0%|          | 1/5506 [00:00<17:33,  5.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:50<00:00,  4.40it/s]\n",
      "  0%|          | 0/5506 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:52<00:00,  4.40it/s]\n",
      "  0%|          | 1/5506 [00:00<17:54,  5.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:56<00:00,  4.38it/s]\n",
      "  0%|          | 1/5506 [00:00<18:05,  5.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  11\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [21:10<00:00,  4.33it/s]\n",
      "  0%|          | 1/5506 [00:00<17:43,  5.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  12\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 5506/5506 [20:43<00:00,  4.43it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.54571588],\n",
       "       [0.55601959],\n",
       "       [0.55286223],\n",
       "       [0.55074705],\n",
       "       [0.55759656],\n",
       "       [0.56365983],\n",
       "       [0.56978939],\n",
       "       [0.57645434],\n",
       "       [0.58311193],\n",
       "       [0.59148558],\n",
       "       [0.60128192],\n",
       "       [0.61130922]])"
      ]
     },
     "execution_count": 5,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sum    \n",
    "#-------------------------------------------------------------------------------   \n",
    "results_sum     = np.zeros((len(stsfull),12)) \n",
    "corrs_sum       = np.zeros((12,1))\n",
    "print(\"Embedding strategy: sum\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "for i in range(12):\n",
    "    print(\"Start from final hidden layer and sum: \",i+1)\n",
    "    print('\\n')\n",
    "    for s in tqdm(range(len(stsfull))):\n",
    "        results_sum[s,i] = bert_semantic_similarity(str(stsfull.iloc[s,5]),\n",
    "                                                str(stsfull.iloc[s,6]),\n",
    "                                                \"sum\",\n",
    "                                                i+1,\n",
    "                                                False)\n",
    "    d = pd.DataFrame({'Score_BERT': results_sum[:,i]})\n",
    "    corrs_sum[i,0] = d[\"Score_BERT\"].corr(stsfull[\"sim\"])\n",
    "corrs_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ds7-SrqrOy9a"
   },
   "outputs": [],
   "source": [
    "FULLsurvey = [corrs_average,corrs_concat,corrs_sum]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LSLWmy_7cYzF"
   },
   "source": [
    "# Survey dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data + sentence preprocessing + normalize score values "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 717753,
     "status": "ok",
     "timestamp": 1613944088889,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "Rmes5YUlcarr",
    "outputId": "e878989e-4e48-41a7-dc50-e08213765ab0"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 1/100 [00:00<00:16,  6.08it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategy: average\n",
      "-----------------------------------------------------------------------\n",
      "Start from final hidden layer and average:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.03it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.05it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.56it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.07it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.07it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.03it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  6\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  4.91it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.57it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.04it/s]\n",
      "  1%|          | 1/100 [00:00<00:16,  6.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.00it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.03it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.05it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  11\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.03it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and average:  12\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.06it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategy: concat\n",
      "-----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  4.98it/s]\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.05it/s]\n",
      "100%|██████████| 100/100 [00:20<00:00,  4.93it/s]\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.08it/s]\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.04it/s]\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.05it/s]\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.03it/s]\n",
      "100%|██████████| 100/100 [00:20<00:00,  4.98it/s]\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.04it/s]\n",
      "100%|██████████| 100/100 [00:20<00:00,  4.94it/s]\n",
      "100%|██████████| 100/100 [00:20<00:00,  4.98it/s]\n",
      "100%|██████████| 100/100 [00:19<00:00,  5.02it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding strategy: sum\n",
      "-----------------------------------------------------------------------\n",
      "Start from final hidden layer and sum:  1\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.07it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  2\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.04it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  3\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.04it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  4\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:20<00:00,  4.95it/s]\n",
      "  1%|          | 1/100 [00:00<00:16,  6.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  5\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.01it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  6\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.02it/s]\n",
      "  1%|          | 1/100 [00:00<00:14,  6.66it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  7\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.05it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  8\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.03it/s]\n",
      "  1%|          | 1/100 [00:00<00:15,  6.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  9\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.04it/s]\n",
      "  1%|          | 1/100 [00:00<00:16,  5.85it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  10\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.03it/s]\n",
      "  1%|          | 1/100 [00:00<00:16,  6.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  11\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.00it/s]\n",
      "  1%|          | 1/100 [00:00<00:16,  6.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start from final hidden layer and sum:  12\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [00:19<00:00,  5.03it/s]\n"
     ]
    }
   ],
   "source": [
    "#read data\n",
    "#-------------------------------------------------------------------------------\n",
    "survey = pd.read_pickle('survey.pkl')\n",
    "\n",
    "# text preprocessing\n",
    "#-------------------------------------------------------------------------------\n",
    "for index, row in survey.iterrows():\n",
    "    survey.loc[index, \"sent_1\"] = preprocess_text(survey.loc[index, \"sent_1\"])\n",
    "    survey.loc[index, \"sent_2\"] = preprocess_text(survey.loc[index, \"sent_2\"])\n",
    "\n",
    "# due to survey design similarity scores are already in range (0,1)\n",
    "# so no need to normalize like for previous datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NLP MODEL\n",
    "#-------------------------------------------------------------------------------\n",
    "#average\n",
    "results_average     = np.zeros((len(survey),12)) \n",
    "corrs_average       = np.zeros((12,1))\n",
    "print(\"Embedding strategy: average\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "for i in range(12):\n",
    "    print(\"Start from final hidden layer and average: \",i+1)\n",
    "    print('\\n')\n",
    "    for s in tqdm(range(len(survey))):\n",
    "            results_average[s,i] = bert_semantic_similarity(str(survey.iloc[s,0]),\n",
    "                                                    str(survey.iloc[s,1]),\n",
    "                                                    \"average\",\n",
    "                                                    i+1,\n",
    "                                                    False)\n",
    "    d = pd.DataFrame({'Score_BERT': results_average[:,i]})\n",
    "    corrs_average[i,0] = d[\"Score_BERT\"].corr(survey[\"score\"])\n",
    "\n",
    "#concat  \n",
    "results_concat    = np.zeros((len(survey),12)) \n",
    "corrs_concat       = np.zeros((12,1))\n",
    "print(\"Embedding strategy: concat\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "for i in range(12):\n",
    "    print(\"Start from final hidden layer and concatenate: \",i+1)\n",
    "    print('\\n')\n",
    "    for s in tqdm(range(len(survey))):\n",
    "        results_concat[s,i] = bert_semantic_similarity(str(survey.iloc[s,0]),\n",
    "                                                str(survey.iloc[s,1]),\n",
    "                                                \"concat\",\n",
    "                                                i+1,\n",
    "                                                False)\n",
    "    d = pd.DataFrame({'Score_BERT': results_concat[:,i]})\n",
    "    corrs_concat[i,0] = d[\"Score_BERT\"].corr(survey[\"score\"])\n",
    "\n",
    "#sum       \n",
    "results_sum     = np.zeros((len(survey),12)) \n",
    "corrs_sum       = np.zeros((12,1))\n",
    "print(\"Embedding strategy: sum\")\n",
    "print(\"-----------------------------------------------------------------------\")\n",
    "for i in range(12):\n",
    "    print(\"Start from final hidden layer and sum: \",i+1)\n",
    "    print('\\n')\n",
    "    for s in tqdm(range(len(survey))):\n",
    "        results_sum[s,i] = bert_semantic_similarity(str(survey.iloc[s,0]),\n",
    "                                                str(survey.iloc[s,1]),\n",
    "                                                \"sum\",\n",
    "                                                i+1,\n",
    "                                                False)\n",
    "    d = pd.DataFrame({'Score_BERT': results_sum[:,i]})\n",
    "    corrs_sum[i,0] = d[\"Score_BERT\"].corr(survey[\"score\"])\n",
    "\n",
    "Csurvey = [corrs_average,corrs_concat,corrs_sum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 541,
     "status": "ok",
     "timestamp": 1613944287625,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "TeKX5fdlk1Kv",
    "outputId": "3ae7fed9-f984-4643-cc64-de8f2bcaaee6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30095393],\n",
       "       [0.30423126],\n",
       "       [0.30181611],\n",
       "       [0.29714807],\n",
       "       [0.28552133],\n",
       "       [0.27008947],\n",
       "       [0.25636052],\n",
       "       [0.24018106],\n",
       "       [0.22346263],\n",
       "       [0.20668065],\n",
       "       [0.19100335],\n",
       "       [0.17729887]])"
      ]
     },
     "execution_count": 22,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 548,
     "status": "ok",
     "timestamp": 1613944303294,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "8BkLadMtk5wh",
    "outputId": "fc98aa4e-be71-42f0-ac57-7e97bb7f1c5e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30095393],\n",
       "       [0.30863485],\n",
       "       [0.3060348 ],\n",
       "       [0.30329809],\n",
       "       [0.29734291],\n",
       "       [0.28909291],\n",
       "       [0.28091583],\n",
       "       [0.27090136],\n",
       "       [0.26094301],\n",
       "       [0.25090895],\n",
       "       [0.24028653],\n",
       "       [0.23062581]])"
      ]
     },
     "execution_count": 23,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_concat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 527,
     "status": "ok",
     "timestamp": 1613944310679,
     "user": {
      "displayName": "Sara Bonati",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GhP7RR9bSO8ueBfRjNzuMdelA6_UOkOGo2DDY7OrA=s64",
      "userId": "09881996973668689480"
     },
     "user_tz": -60
    },
    "id": "BAbuAZbYk7iT",
    "outputId": "6ba91000-1c7a-4737-c1a6-b3bffca0f21f"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.30095393],\n",
       "       [0.30423126],\n",
       "       [0.30181612],\n",
       "       [0.29714807],\n",
       "       [0.28552127],\n",
       "       [0.27008968],\n",
       "       [0.25636034],\n",
       "       [0.24018106],\n",
       "       [0.22346223],\n",
       "       [0.20668128],\n",
       "       [0.19100386],\n",
       "       [0.17729893]])"
      ]
     },
     "execution_count": 24,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corrs_sum"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "apply_model_BERT.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "00c146ccb5c348928aed2062ed86cb49": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "01662387a180465b948d30e20f8f660f": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "11e48d8bc4c849239de556ea6bf8698c": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "12c2f2a6af8e4e41ae772a87bb662dc6": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1bb2a2f5a62149fab6c891f42a688a53": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "244c661ccfce4e1094ad53c17a08d481": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "303639e5451f40f6874033005b5246a7": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "30e03847d24b4147b9f04ac65500eea8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ac0816f5a0b941d7882c08f86256b72d",
      "placeholder": "​",
      "style": "IPY_MODEL_cd27dc0d2c374be8a7cab7fbc208e68c",
      "value": " 433/433 [00:00&lt;00:00, 567B/s]"
     }
    },
    "34433c17bb104ba08dceb07d90013de5": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aac7e2da9ac4f9b8ea0ab0ba7322b1a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3aae8ee4d34649808c68fe1c8d234ca2": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_34433c17bb104ba08dceb07d90013de5",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_fbba757a8bb8435c9ae858ec49ea1b2e",
      "value": 440473133
     }
    },
    "3ae3ec03f4204d51a8a4561bc9bb6721": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "3b10debb7dbb475ebd6688aafe35f467": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "3db710aeae2742d49e92b9ceb6000b8e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_01662387a180465b948d30e20f8f660f",
      "placeholder": "​",
      "style": "IPY_MODEL_777f686bc8e8472382401b6658f96b21",
      "value": " 433/433 [00:00&lt;00:00, 1.01kB/s]"
     }
    },
    "413384e00a07494285700f23c8b02020": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_a840bd9b4b5a416bab9fddeff8ffee78",
       "IPY_MODEL_c2bae92977564ad595514b20d2761d09"
      ],
      "layout": "IPY_MODEL_8363e1fe667943ebad3cb9e4ff323cec"
     }
    },
    "42243a9ed0af44b8ba8fd3f5ba0f9704": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "43ba3b28433b4822bbb266f9e65beeff": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_d1fe201f14f94f8284ccad1eaf93bef9",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_d1f0fde993984933a74d621f862fd601",
      "value": 433
     }
    },
    "47f5a517613e43c0a4aedf09d737cacf": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "4f1d90b0844244578b221b0a95320638": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "56d307adf23743a38cd4e6ec6a589652": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "66e00e78fef14b76826a551e783d849e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e45d520c20fd49dd83c32637f8a59f36",
       "IPY_MODEL_d37458ea10b54a4ba7a3e4a0905b3767"
      ],
      "layout": "IPY_MODEL_c2b801e36b784b9989204fe51e2a2f03"
     }
    },
    "6ead35d34c5843e48b47815393c0e28a": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "777f686bc8e8472382401b6658f96b21": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "78f225744ee0476dbbe4f4988cf747c6": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_4f1d90b0844244578b221b0a95320638",
      "placeholder": "​",
      "style": "IPY_MODEL_bf0d904f740b412f92f0db5ace5e330e",
      "value": " 440M/440M [00:08&lt;00:00, 50.2MB/s]"
     }
    },
    "8363e1fe667943ebad3cb9e4ff323cec": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "936f8f62197c4912887da8b135c9edaa": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9b4324d5b9a341e09e54cfbe31665b19": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_42243a9ed0af44b8ba8fd3f5ba0f9704",
      "placeholder": "​",
      "style": "IPY_MODEL_f114a0a670814cc3a814d14ec00aee02",
      "value": " 232k/232k [00:00&lt;00:00, 2.06MB/s]"
     }
    },
    "9bf155cba51a412486c972e41168d863": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_936f8f62197c4912887da8b135c9edaa",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_303639e5451f40f6874033005b5246a7",
      "value": 231508
     }
    },
    "a840bd9b4b5a416bab9fddeff8ffee78": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_12c2f2a6af8e4e41ae772a87bb662dc6",
      "max": 231508,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_56d307adf23743a38cd4e6ec6a589652",
      "value": 231508
     }
    },
    "ac0816f5a0b941d7882c08f86256b72d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b1af0142f97543c1b67f43810155f818": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_3aae8ee4d34649808c68fe1c8d234ca2",
       "IPY_MODEL_78f225744ee0476dbbe4f4988cf747c6"
      ],
      "layout": "IPY_MODEL_244c661ccfce4e1094ad53c17a08d481"
     }
    },
    "bbe0e87791e64f249130d09446c5ae1e": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf0d904f740b412f92f0db5ace5e330e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "c2b801e36b784b9989204fe51e2a2f03": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c2bae92977564ad595514b20d2761d09": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3aac7e2da9ac4f9b8ea0ab0ba7322b1a",
      "placeholder": "​",
      "style": "IPY_MODEL_47f5a517613e43c0a4aedf09d737cacf",
      "value": " 232k/232k [00:00&lt;00:00, 746kB/s]"
     }
    },
    "c5ad14ec5aed40f49b921a8aee7a55c8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_fe98e7a6fee84dbd828f62ca22b02672",
       "IPY_MODEL_30e03847d24b4147b9f04ac65500eea8"
      ],
      "layout": "IPY_MODEL_d57100b06bb942acb4ee8eda405caae3"
     }
    },
    "cd27dc0d2c374be8a7cab7fbc208e68c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "d1f0fde993984933a74d621f862fd601": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "d1fe201f14f94f8284ccad1eaf93bef9": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "d37458ea10b54a4ba7a3e4a0905b3767": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bbe0e87791e64f249130d09446c5ae1e",
      "placeholder": "​",
      "style": "IPY_MODEL_f2d8851289ef44f183a264aed1d92ce8",
      "value": " 440M/440M [00:08&lt;00:00, 51.0MB/s]"
     }
    },
    "d57100b06bb942acb4ee8eda405caae3": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "debb9bd561e94e1994b379a143b82247": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_43ba3b28433b4822bbb266f9e65beeff",
       "IPY_MODEL_3db710aeae2742d49e92b9ceb6000b8e"
      ],
      "layout": "IPY_MODEL_1bb2a2f5a62149fab6c891f42a688a53"
     }
    },
    "e45d520c20fd49dd83c32637f8a59f36": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_3ae3ec03f4204d51a8a4561bc9bb6721",
      "max": 440473133,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_3b10debb7dbb475ebd6688aafe35f467",
      "value": 440473133
     }
    },
    "f114a0a670814cc3a814d14ec00aee02": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2d8851289ef44f183a264aed1d92ce8": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "fbab3b2912a246acb796d22e4c13a48d": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_9bf155cba51a412486c972e41168d863",
       "IPY_MODEL_9b4324d5b9a341e09e54cfbe31665b19"
      ],
      "layout": "IPY_MODEL_11e48d8bc4c849239de556ea6bf8698c"
     }
    },
    "fbba757a8bb8435c9ae858ec49ea1b2e": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "fe98e7a6fee84dbd828f62ca22b02672": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "Downloading: 100%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_6ead35d34c5843e48b47815393c0e28a",
      "max": 433,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_00c146ccb5c348928aed2062ed86cb49",
      "value": 433
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
